import os
import numpy as np
import torch
import torch.nn as nn
from models import AutoEncoder

# === å‚æ•°è®¾ç½® ===
txt_file = "data/010217A.txt"  # æ›¿æ¢æˆä½ è‡ªå·±çš„æ–‡ä»¶è·¯å¾„
window_size = 60
threshold = 0.3  # MSE é‡æ„è¯¯å·®é˜ˆå€¼

# === åŠ è½½æ¨¡å‹ ===
model = AutoEncoder()
model.load_state_dict(torch.load("output/spo2_autoencoder.pth"))
model.eval()

loss_fn = nn.MSELoss()

# === è¯»å– SpO2 æ•°æ® ===
spo2_values = []
with open(txt_file, 'r') as f:
    for line in f:
        try:
            val = float(line.strip())
            spo2_values.append(val)
        except:
            continue
data = np.array(spo2_values, dtype=np.float32)

# === åˆ‡ç‰‡ä¸ºçª—å£ ===
segments = []
for i in range(len(data) - window_size + 1):
    segment = data[i:i + window_size]
    segments.append(segment)
segments = np.stack(segments)  # [N, 60]
inputs = torch.tensor(segments)

# === æ¨ç†å¹¶è®¡ç®— Loss ===
with torch.no_grad():
    outputs = model(inputs)
    losses = torch.mean((outputs - inputs) ** 2, dim=1)

# === è¾“å‡ºå‰å‡ é¡¹ Loss
for i in range(min(20, len(losses))):
    status = "âš ï¸ å¼‚å¸¸" if losses[i] > threshold else "âœ… æ­£å¸¸"
    print(f"[{i}] Loss: {losses[i]:.6f} {status}")

# === ç»Ÿè®¡å¼‚å¸¸çª—å£æ•°é‡
anomaly_count = (losses > threshold).sum().item()
print(f"\nğŸ“Š å¼‚å¸¸çª—å£æ•°: {anomaly_count} / {len(losses)}")
